"""
ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸

ë‹¤ì–‘í•œ ìµœì í™” ì˜µì…˜ì„ ì ìš©í•˜ì—¬ ì†ë„ë¥¼ ì¸¡ì •í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
1. ê¸°ë³¸ ì„¤ì • (chunk_size=1000, overlap=200, evidence=full)
2. ì¶œì²˜ ì—°ê²° off (evidence=off)
3. í° ì²­í¬ í¬ê¸° (chunk_size=4000, overlap=100)
4. ì‹œë§¨í‹± ì²­í‚¹ (semantic chunking)
5. ì¡°í•©: í° ì²­í¬ + ì¶œì²˜ off
"""

import sys
import time
import os
from pathlib import Path
from contextlib import contextmanager

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from pdf2bpmn.extractors.pdf_extractor import PDFExtractor
from pdf2bpmn.extractors.entity_extractor import EntityExtractor
from pdf2bpmn.graph.neo4j_client import Neo4jClient
from pdf2bpmn.workflow.graph import PDF2BPMNWorkflow
from pdf2bpmn.config import Config


@contextmanager
def timer(name: str):
    """ì‹œê°„ ì¸¡ì • ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    start = time.time()
    yield
    elapsed = time.time() - start
    print(f"   â±ï¸ [{name}] {elapsed:.2f}ì´ˆ")


class PerformanceTest:
    """ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.results = []
    
    def setup(self):
        """ì´ˆê¸°í™”"""
        self.neo4j = Neo4jClient()
        self._clear_neo4j()
        self.neo4j.init_schema()
    
    def teardown(self):
        """ì •ë¦¬"""
        if self.neo4j:
            self.neo4j.close()
    
    def _clear_neo4j(self):
        """Neo4j ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with self.neo4j.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
    
    def run_test(self, name: str, config: dict, pdf_path: str):
        """íŠ¹ì • ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\n{'='*70}")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {name}")
        print(f"{'='*70}")
        print(f"ì„¤ì •: {config}")
        
        # ì„¤ì • ì ìš©
        original_chunk_size = Config.CHUNK_SIZE
        original_chunk_overlap = Config.CHUNK_OVERLAP
        original_evidence_mode = Config.EVIDENCE_MODE
        original_chunking_strategy = Config.CHUNKING_STRATEGY
        
        Config.CHUNK_SIZE = config.get("chunk_size", Config.CHUNK_SIZE)
        Config.CHUNK_OVERLAP = config.get("chunk_overlap", Config.CHUNK_OVERLAP)
        Config.EVIDENCE_MODE = config.get("evidence_mode", Config.EVIDENCE_MODE)
        Config.CHUNKING_STRATEGY = config.get("chunking_strategy", Config.CHUNKING_STRATEGY)
        
        try:
            # Neo4j ì´ˆê¸°í™”
            self._clear_neo4j()
            
            test_start = time.time()
            timings = {}
            
            # PDF ì¶”ì¶œ
            with timer("PDF ì¶”ì¶œ"):
                pdf_extractor = PDFExtractor(
                    chunk_size=config.get("chunk_size"),
                    chunk_overlap=config.get("chunk_overlap"),
                    chunking_strategy=config.get("chunking_strategy")
                )
                document, sections, chunks = pdf_extractor.extract_document(pdf_path)
                timings["pdf_extraction"] = time.time() - test_start
            
            print(f"   ğŸ“„ ë¬¸ì„œ: {document.title}")
            print(f"   ğŸ“‘ í˜ì´ì§€: {document.page_count}")
            print(f"   ğŸ“‹ ì²­í¬ ìˆ˜: {len(chunks)}")
            print(f"   ğŸ“Š ì„¹ì…˜ ìˆ˜: {len(sections)}")
            
            # ì²­í¬ í‰ê·  í¬ê¸°
            if chunks:
                avg_chunk_size = sum(len(c.text) for c in chunks) / len(chunks)
                print(f"   ğŸ“ í‰ê·  ì²­í¬ í¬ê¸°: {avg_chunk_size:.0f}ì")
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            workflow = PDF2BPMNWorkflow()
            
            state = {
                "pdf_paths": [pdf_path],
                "documents": [],
                "sections": [],
                "reference_chunks": [],
                "processes": [],
                "tasks": [],
                "roles": [],
                "gateways": [],
                "events": [],
                "skills": [],
                "dmn_decisions": [],
                "dmn_rules": [],
                "evidences": [],
                "open_questions": [],
                "resolved_questions": [],
                "current_question": None,
                "user_answer": None,
                "confidence_threshold": Config.CONFIDENCE_THRESHOLD,
                "current_step": "ingest_pdf",
                "error": None,
                "bpmn_xml": None,
                "bpmn_xmls": {},
                "bpmn_files": {},
                "skill_docs": {},
                "dmn_xml": None
            }
            
            # Step 1: Ingest PDF
            step_start = time.time()
            result = workflow.ingest_pdf(state)
            state.update(result)
            timings["ingest_pdf"] = time.time() - step_start
            
            # Step 2: Segment sections
            step_start = time.time()
            result = workflow.segment_sections(state)
            state.update(result)
            timings["segment_sections"] = time.time() - step_start
            
            # Step 3: Extract candidates
            step_start = time.time()
            result = workflow.extract_candidates(state)
            state.update(result)
            timings["extract_candidates"] = time.time() - step_start
            
            # Step 4: Normalize
            step_start = time.time()
            result = workflow.normalize_entities(state)
            state.update(result)
            timings["normalize_entities"] = time.time() - step_start
            
            # Step 5: Generate skills
            step_start = time.time()
            result = workflow.generate_skills(state)
            state.update(result)
            timings["generate_skills"] = time.time() - step_start
            
            # Step 6: Generate DMN
            step_start = time.time()
            result = workflow.generate_dmn(state)
            state.update(result)
            timings["generate_dmn"] = time.time() - step_start
            
            # Step 7: Assemble BPMN
            step_start = time.time()
            result = workflow.assemble_bpmn(state)
            state.update(result)
            timings["assemble_bpmn"] = time.time() - step_start
            
            # Step 8: Export
            step_start = time.time()
            result = workflow.export_artifacts(state)
            state.update(result)
            timings["export_artifacts"] = time.time() - step_start
            
            total_time = time.time() - test_start
            timings["total"] = total_time
            
            # ê²°ê³¼ ìˆ˜ì§‘
            process_count = len(state.get("processes", []))
            task_count = len(state.get("tasks", []))
            role_count = len(state.get("roles", []))
            
            print(f"\nğŸ“Š ê²°ê³¼:")
            print(f"   í”„ë¡œì„¸ìŠ¤: {process_count}ê°œ")
            print(f"   íƒœìŠ¤í¬: {task_count}ê°œ")
            print(f"   ì—­í• : {role_count}ê°œ")
            print(f"   ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
            
            result_data = {
                "name": name,
                "config": config,
                "chunk_count": len(chunks),
                "avg_chunk_size": avg_chunk_size if chunks else 0,
                "process_count": process_count,
                "task_count": task_count,
                "role_count": role_count,
                "timings": timings
            }
            
            self.results.append(result_data)
            workflow.neo4j.close()
            
            return result_data
            
        finally:
            # ì›ë˜ ì„¤ì • ë³µì›
            Config.CHUNK_SIZE = original_chunk_size
            Config.CHUNK_OVERLAP = original_chunk_overlap
            Config.EVIDENCE_MODE = original_evidence_mode
            Config.CHUNKING_STRATEGY = original_chunking_strategy
    
    def print_comparison(self):
        """ê²°ê³¼ ë¹„êµ ì¶œë ¥"""
        if not self.results:
            return
        
        print(f"\n{'='*70}")
        print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print(f"{'='*70}")
        
        # í—¤ë”
        print(f"\n{'í…ŒìŠ¤íŠ¸':<30} {'ì²­í¬ìˆ˜':<8} {'í‰ê· ì²­í¬':<10} {'ì´ì‹œê°„':<10} {'PDF':<8} {'ì¶”ì¶œ':<8} {'ì •ê·œí™”':<8}")
        print("-" * 70)
        
        baseline = self.results[0] if self.results else None
        
        for result in self.results:
            timings = result["timings"]
            name = result["name"][:28]
            chunk_count = result["chunk_count"]
            avg_chunk = f"{result['avg_chunk_size']:.0f}"
            total = f"{timings['total']:.2f}"
            pdf_time = f"{timings.get('pdf_extraction', 0):.2f}"
            extract_time = f"{timings.get('extract_candidates', 0):.2f}"
            normalize_time = f"{timings.get('normalize_entities', 0):.2f}"
            
            # ê°œì„ ìœ¨ ê³„ì‚°
            if baseline and baseline["timings"]["total"] > 0:
                improvement = ((baseline["timings"]["total"] - timings["total"]) / baseline["timings"]["total"]) * 100
                improvement_str = f" ({improvement:+.1f}%)" if improvement != 0 else ""
            else:
                improvement_str = ""
            
            print(f"{name:<30} {chunk_count:<8} {avg_chunk:<10} {total:<10}{improvement_str} {pdf_time:<8} {extract_time:<8} {normalize_time:<8}")
        
        print(f"\n{'='*70}")
        print("ìƒì„¸ ì‹œê°„ ë¶„ì„")
        print(f"{'='*70}")
        
        for result in self.results:
            print(f"\n{result['name']}:")
            timings = result["timings"]
            for step, duration in sorted(timings.items(), key=lambda x: x[1], reverse=True):
                if step != "total":
                    percentage = (duration / timings["total"]) * 100
                    print(f"   {step:<20}: {duration:>6.2f}ì´ˆ ({percentage:>5.1f}%)")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ PDF íŒŒì¼ ì°¾ê¸°
    possible_paths = [
        Path(__file__).parent.parent / "doc" / "purchase_approval_process.pdf",
        Path(__file__).parent.parent / "uploads" / "purchase_approval_process.pdf",
    ]
    
    pdf_path = None
    for path in possible_paths:
        if path.exists():
            pdf_path = path
            break
    
    if not pdf_path:
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ ê²½ë¡œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤:")
        for path in possible_paths:
            print(f"     - {path}")
        return
    
    test = PerformanceTest()
    test.setup()
    
    try:
        # í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ì„¤ì •
        test.run_test(
            "1. ê¸°ë³¸ ì„¤ì •",
            {
                "chunk_size": 1000,
                "chunk_overlap": 200,
                "evidence_mode": "full",
                "chunking_strategy": "fixed"
            },
            str(pdf_path)
        )
        
        # í…ŒìŠ¤íŠ¸ 2: ì¶œì²˜ ì—°ê²° off
        test.run_test(
            "2. ì¶œì²˜ ì—°ê²° OFF",
            {
                "chunk_size": 1000,
                "chunk_overlap": 200,
                "evidence_mode": "off",
                "chunking_strategy": "fixed"
            },
            str(pdf_path)
        )
        
        # í…ŒìŠ¤íŠ¸ 3: í° ì²­í¬ í¬ê¸°
        test.run_test(
            "3. í° ì²­í¬ (4000ì, ì˜¤ë²„ë© 100)",
            {
                "chunk_size": 4000,
                "chunk_overlap": 100,
                "evidence_mode": "full",
                "chunking_strategy": "fixed"
            },
            str(pdf_path)
        )
        
        # í…ŒìŠ¤íŠ¸ 4: ì‹œë§¨í‹± ì²­í‚¹
        test.run_test(
            "4. ì‹œë§¨í‹± ì²­í‚¹",
            {
                "chunk_size": 1000,
                "chunk_overlap": 50,
                "evidence_mode": "full",
                "chunking_strategy": "semantic"
            },
            str(pdf_path)
        )
        
        # í…ŒìŠ¤íŠ¸ 5: ì¡°í•© (í° ì²­í¬ + ì¶œì²˜ off)
        test.run_test(
            "5. ì¡°í•© (í° ì²­í¬ + ì¶œì²˜ OFF)",
            {
                "chunk_size": 4000,
                "chunk_overlap": 100,
                "evidence_mode": "off",
                "chunking_strategy": "fixed"
            },
            str(pdf_path)
        )
        
        # ê²°ê³¼ ë¹„êµ
        test.print_comparison()
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        test.teardown()


if __name__ == "__main__":
    main()

